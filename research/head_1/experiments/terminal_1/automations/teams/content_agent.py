import logging
import os
# Placeholder for Gemma3 integration

class ContentAgent:
    def __init__(self, model="gemma3", workspace_root=None):
        self.model = model
        self.logger = logging.getLogger('ContentAgent')
        self.workspace_root = workspace_root or os.getcwd()  # Always set workspace_root

    def process(self, task, context):
        # Here you would call Gemma3 via API or local endpoint
        query = task.get('query', '')
        self.logger.info(f"ContentAgent ({self.model}) processing: {query}")
        return f"[Gemma3] Content for: {query} (context: {len(context) if context else 0} files)"

    def generate_docs(self, index):
        """
        Generate comprehensive documentation for the workspace:
        - Workspace overview
        - Per-file/module summaries
        - Per-class/function docstrings (if possible)
        - Notes and actionable insights
        - Appends to existing documentation instead of overwriting
        """
        from datetime import datetime
        self.logger.info("Generating comprehensive documentation and actionable insights.")
        docs = {}
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        overview = [f"\n---\n## Documentation Run: {timestamp}\n", "# Workspace Documentation\n", "## Overview\n", "This documentation was auto-generated by ContentAgent.\n"]
        file_summaries = []
        notes = []
        insights = []
        all_files = index.get('all_files', [])
        for file_info in all_files:
            file_path = file_info['path']
            summary = f"### {file_path}\n"
            summary += f"- Size: {file_info.get('size', 'N/A')} bytes\n"
            summary += f"- Last modified: {file_info.get('last_modified', 'N/A')}\n"
            summary += f"- Type: {file_info.get('type', 'N/A')}\n"
            # If markdown, include excerpt
            if file_info.get('type') == 'markdown':
                abs_path = os.path.join(self.workspace_root, file_path) if hasattr(self, 'workspace_root') else file_path
                try:
                    with open(abs_path, 'r', encoding='utf-8') as f:
                        excerpt = ''.join([next(f) for _ in range(5)])
                    summary += f"- Excerpt:\n{excerpt}\n"
                except Exception as e:
                    summary += f"- Excerpt: (Could not read: {e})\n"
            summary += f"- Description: Auto-generated summary for `{file_path}`.\n"
            note = f"Note: `{file_path}` last modified on {file_info.get('last_modified', 'N/A')} and is of type {file_info.get('type', 'N/A')}."
            notes.append(note)
            if file_info.get('type') == 'script' and file_info.get('size', 0) > 10000:
                insights.append(f"Actionable Insight: Consider refactoring `{file_path}` (large script file).")
            if file_info.get('type') == 'notebook':
                insights.append(f"Actionable Insight: Review `{file_path}` for reproducibility and documentation.")
            file_summaries.append(summary)
        overview.append("\n".join(file_summaries))
        overview.append("\n## Notes\n" + "\n".join(notes))
        overview.append("\n## Actionable Insights\n" + ("\n".join(insights) if insights else "No actionable insights detected."))
        # Append to existing documentation if it exists
        doc_path = os.path.join("docs", "README_AUTO.md")
        if os.path.exists(doc_path):
            with open(doc_path, "r", encoding="utf-8") as f:
                existing = f.read()
            docs[doc_path] = existing + "\n\n" + "\n".join(overview)
        else:
            docs[doc_path] = "\n".join(overview)
        return docs
