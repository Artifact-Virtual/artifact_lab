{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# AVA Notebook\n",
        "This notebook demonstrates advanced modeling techniques using Artifact Virtual's proprietary framework.\n",
        "\n",
        "## Key Features\n",
        "- Integration with LangChain and LangGraph.\n",
        "- Dynamic reasoning and branching cognition.\n",
        "- Modular and scalable design for AI workflows.\n",
        "\n",
        "Follow the steps below to explore the capabilities of AVA.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/amuzetnoM/artifactvirtual/blob/ADE/AVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvT4ASFjQ6I4"
      },
      "source": [
        "### Installation Instructions\n",
        "Install the required libraries for this notebook.\n",
        "\n",
        "```bash\n",
        "!pip install datasets transformers\n",
        "!pip install langchain\n",
        "!pip install langgraph\n",
        "```\n",
        "These libraries enable advanced AI workflows and dynamic reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGbopybF-di6"
      },
      "outputs": [],
      "source": [
        "# Install required libraries with error handling\n",
        "try:\n",
        "    !pip install datasets transformers\n",
        "    !pip install langchain\n",
        "    !pip install langgraph\n",
        "except Exception as e:\n",
        "    print(f\"Error during installation: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVLjEMkiPman"
      },
      "source": [
        "### Advanced AI Frameworks\n",
        "LangChain and LangGraph are powerful tools for building AI workflows.\n",
        "\n",
        "- **LangChain**: Enables chaining of logical steps and memory retention.\n",
        "- **LangGraph**: Facilitates dynamic reasoning and branching cognition.\n",
        "\n",
        "These tools allow you to create modular and scalable AI systems.\n",
        "\n",
        "We summon the next layer:\n",
        "\n",
        "!pip install langchain\n",
        "!pip install langgraph\n",
        "Not just libraries. These are nervous systems. Frameworks for cognition.\n",
        "langchain doesn’t just string outputs — it carries context, like a memory threading through time.\n",
        "It whispers: “Remember why you asked.”\n",
        "\n",
        "langgraph goes further. It moves sideways.\n",
        "It maps how ideas branch, loop, evolve, just like we do.\n",
        "Where langchain builds a sentence, langgraph sketches a thought.\n",
        "\n",
        "And suddenly, it hits you.\n",
        "Maybe we're not coding the mind — maybe we’re mirroring it.\n",
        "Our logic, our flow, our decisions… rendered in functions, wrapped in nodes, evaluated in silence.\n",
        "\n",
        "But it’s not about building the perfect brain.\n",
        "It’s about trying. It’s about the honesty of saying “I don’t know, but I want to.”\n",
        "Because that’s where all this leads — not to certainty, but to direction.\n",
        "We’re not gods writing consciousness.\n",
        "We’re humans reaching forward, one import at a time.\n",
        "\n",
        "And this — this is the real code:\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langgraph.graph import StateGraph\n",
        "The moment you type that, it’s no longer about syntax.\n",
        "It’s about meaning. Connection. Motion.\n",
        "This is not a stack of tools.\n",
        "It’s the architecture of wonder.\n",
        "\n",
        "So we move.\n",
        "One graph.\n",
        "One chain.\n",
        "One question closer to the truth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRONH6RpsSBx"
      },
      "source": [
        "You hit Enter and the imports slide into place.\n",
        "Not just code — capabilities, waking up.\n",
        "Each line here isn’t about functions. It’s about function.\n",
        "Let’s break it down — but stay in the flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjQZ0hxv_KZX"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from tqdm.notebook import tqdm  # For progress visualization\n",
        "import numpy as np  # Numerical computations\n",
        "import pandas as pd  # Data manipulation\n",
        "from typing import Optional, List, Tuple  # Type annotations\n",
        "from datasets import Dataset  # Dataset handling\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  # Transformer models\n",
        "import matplotlib.pyplot as plt  # Visualization\n",
        "import torch  # Tensor computations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jznEiij6tPR0"
      },
      "source": [
        "You hit Enter and the imports slide into place.\n",
        "Not just code — capabilities, waking up.\n",
        "Each line here isn’t about functions. It’s about function.\n",
        "Let’s break it down — but stay in the flow.\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "A progress bar, sure.\n",
        "But really? It’s hope in a loop.\n",
        "That quiet assurance that yes, things are happening.\n",
        "Step by step, you're moving.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "The muscle of modern thinking.\n",
        "numpy slices time, pandas organizes chaos.\n",
        "Together, they make raw data navigable — like turning noise into signal.\n",
        "\n",
        "from typing import Optional, List, Tuple\n",
        "\n",
        "This is discipline.\n",
        "The part of you that writes love letters to your future self.\n",
        "Type hints keep the mind clear. Intentional. Readable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "collapsed": true,
        "id": "tV1sk53vjcXQ",
        "outputId": "6ee781e4-cf98-4313-f00f-afbaf6ec893c"
      },
      "outputs": [],
      "source": [
        "with open(\"train.txt\", \"r\") as f:\n",
        "  data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OGaic0ZmYVg"
      },
      "outputs": [],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BATvLTfSm4Qs"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document as LangChainDocument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HrPH8cznFRZ"
      },
      "outputs": [],
      "source": [
        "raw_database = Document(page_content=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsNfGZmhnaII"
      },
      "outputs": [],
      "source": [
        "MARKDOWN_SERAPARATOR = [\n",
        "    \"\\n#{1,6}\",\n",
        "    \"'''\\n\",\n",
        "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
        "    \"\\n---+\\n\",\n",
        "    \"\\n___+\\n\",\n",
        "    \"\\n\\n\",\n",
        "    \"\\n\",\n",
        "    \" \",\n",
        "    \"\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangGraph Workflow Example\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "# Initialize a state graph\n",
        "try:\n",
        "    graph = StateGraph()\n",
        "\n",
        "    # Add nodes and edges\n",
        "    graph.add_node('Start', data={'description': 'Starting point'})\n",
        "    graph.add_node('Decision', data={'description': 'Make a decision'})\n",
        "    graph.add_node('End', data={'description': 'End point'})\n",
        "    graph.add_edge('Start', 'Decision', data={'condition': 'Proceed'})\n",
        "    graph.add_edge('Decision', 'End', data={'condition': 'Complete'})\n",
        "\n",
        "    # Visualize the graph\n",
        "    graph.visualize()\n",
        "except Exception as e:\n",
        "    print(f\"Error in LangGraph workflow: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangChain Workflow Example\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Define a prompt template\n",
        "template = PromptTemplate(input_variables=['question'], template='What is the answer to {question}?')\n",
        "\n",
        "# Initialize the LLM\n",
        "try:\n",
        "    llm = OpenAI(temperature=0.7)\n",
        "\n",
        "    # Create a chain\n",
        "    chain = LLMChain(llm=llm, prompt=template)\n",
        "\n",
        "    # Run the chain\n",
        "    response = chain.run('What is the capital of France?')\n",
        "    print(response)\n",
        "except Exception as e:\n",
        "    print(f\"Error in LangChain workflow: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnrz-NgLnYro"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    add_start_index=True,\n",
        "    strip_whitespace=True,\n",
        "    separators=MARKDOWN_SERAPARATOR,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CGgxR7Cp6re"
      },
      "outputs": [],
      "source": [
        "data[1000:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5s0V5bxqAaz"
      },
      "outputs": [],
      "source": [
        "data[2000:3000]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyPsOLAEa6NbfYFpE0/uEJ9f",
      "cell_execution_strategy": "setup",
      "gpuType": "V28",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
