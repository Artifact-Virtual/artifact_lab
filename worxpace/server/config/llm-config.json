{
  "defaultProvider": "openai",
  "providers": {
    "openai": {
      "apiKey": "",
      "model": "gpt-4o",
      "enabled": true
    },
    "gemini": {
      "apiKey": "",
      "model": "gemini-2.5-flash",
      "enabled": true
    },
    "ollama": {
      "endpoint": "http://localhost:11434",
      "model": "llama3.2:3b",
      "enabled": false
    },
    "llmstudio": {
      "endpoint": "http://localhost:1234",
      "model": "local-model",
      "enabled": false
    }
  },
  "fallbackOrder": ["openai", "gemini", "ollama", "llmstudio"]
}